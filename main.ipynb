{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba78ecf5",
   "metadata": {},
   "source": [
    "### Data Overview\n",
    "`[using dummy and generated data] **as long as there is lat and long attribute**` <br />\n",
    "\n",
    "to create the algorithm and pivot points to optimize search algorithm in database and server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538ba39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# dummy data first\n",
    "\n",
    "'''\n",
    "data json must be consist of [{...}, {...}, ..., {...},]\n",
    "where the {...} consist of \n",
    "- _id: int or str\n",
    "- latitude: float\n",
    "- longitude: float\n",
    "'''\n",
    "fname = \"data/generated.json\"\n",
    "\n",
    "datafile = None\n",
    "\n",
    "try:\n",
    "    with open(fname, \"r\") as file:\n",
    "        datafile = json.load(file)\n",
    "\n",
    "except json.JSONDecodeError as e:\n",
    "    print(\"Failed to decode JSON:\", e)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"The file was not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8afbcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e74110",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(datafile[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b880df",
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb37ed1b",
   "metadata": {},
   "source": [
    "### Map data into Pandas Dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202ff1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\n",
    "    # main attributes \n",
    "    '_id', \n",
    "    'index', \n",
    "    'latitude',\n",
    "    'longitude',\n",
    "    \n",
    "    # optional attributes \n",
    "    'isActive',\n",
    "    'address',\n",
    "    'company',\n",
    "    'name'\n",
    "]\n",
    "\n",
    "temp_data = {\n",
    "    'uuid': [],\n",
    "    'id_index': [],\n",
    "    'lat': [],\n",
    "    'long' : [],\n",
    "    \n",
    "    # optional attributes \n",
    "    'isActive' : [],\n",
    "    'address' : [],\n",
    "    'company' : [],\n",
    "    'name': [],\n",
    "    \n",
    "}\n",
    "for d in datafile:\n",
    "    temp_data['uuid'].append(d['_id'])\n",
    "    temp_data['id_index'].append(d['index'])\n",
    "    temp_data['lat'].append(d['latitude'])\n",
    "    temp_data['long'].append(d['longitude'])\n",
    "    temp_data['isActive'].append(d['isActive'])\n",
    "    temp_data['address'].append(d['address'])\n",
    "    temp_data['company'].append(d['company'])\n",
    "    temp_data['name'].append(d['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcca34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(temp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaf763d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3a6005",
   "metadata": {},
   "source": [
    "### Geopandas Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee54f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    df,\n",
    "    geometry=gpd.points_from_xy(df[\"long\"], df[\"lat\"]),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e8df7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gdf = gdf.set_crs(epsg=4326)\n",
    "\n",
    "ax = gdf.plot(\n",
    "    figsize=(10, 6),\n",
    "    color=\"red\",\n",
    "    markersize=20\n",
    ")\n",
    "\n",
    "ax.set_title(\"Data Points Map\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4616f4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gdf = gdf.set_crs(epsg=4326)\n",
    "\n",
    "ax = gdf.plot(\n",
    "    figsize=(10, 6),\n",
    "    color=\"red\",\n",
    "    markersize=20\n",
    ")\n",
    "\n",
    "center_lat = -6.2\n",
    "center_lon = 106.8\n",
    "center_point = gpd.GeoSeries(\n",
    "    [Point(center_lon, center_lat)],\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "gdf_3857 = gdf.to_crs(epsg=3857)\n",
    "center_3857 = center_point.to_crs(epsg=3857)\n",
    "\n",
    "radius_km = 5000\n",
    "radius_m = radius_km * 1000\n",
    "\n",
    "circle = center_3857.buffer(radius_m)\n",
    "\n",
    "circle_4326 = circle.to_crs(epsg=4326)\n",
    "center_4326 = center_3857.to_crs(epsg=4326)\n",
    "\n",
    "\n",
    "circle_4326.plot(\n",
    "    ax=ax,\n",
    "    facecolor=\"none\",\n",
    "    edgecolor=\"blue\",\n",
    "    linewidth=2,\n",
    "    label=\"Radius 5000 km\"\n",
    ")\n",
    "\n",
    "center_4326.plot(\n",
    "    ax=ax,\n",
    "    color=\"blue\",\n",
    "    markersize=50,\n",
    "    marker=\"x\",\n",
    "    label=\"Center\"\n",
    ")\n",
    "\n",
    "ax.set_title(\"Data Points Map with Radius\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b448a998",
   "metadata": {},
   "source": [
    "### Working on Creating and Designing the Clustering Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d18fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sliding window the latitude\n",
    "df['dist_next_lat'] = df['lat'].diff().abs()\n",
    "\n",
    "# sliding window the latitude\n",
    "df['dist_next_long'] = df['long'].diff().abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531f4576",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370550c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dist_next_lat'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87796c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dist_next_long'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a9216f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dist_next_long'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd32b2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dist_next_lat'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c00688",
   "metadata": {},
   "source": [
    "#### Plot the data distribution and Subplot data `long and lat distance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1c5d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "data = df['dist_next_lat'].dropna()\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axs[0].boxplot(data, vert=True, showfliers=True)\n",
    "axs[0].set_title(\"Boxplot dist_next_lat\")\n",
    "axs[0].set_ylabel(\"Latitude Difference\")\n",
    "axs[0].grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "axs[1].hist(data, bins=30, density=True, alpha=0.6)\n",
    "\n",
    "mu, std = norm.fit(data)\n",
    "\n",
    "x = np.linspace(data.min(), data.max(), 100)\n",
    "p = norm.pdf(x, mu, std)\n",
    "\n",
    "axs[1].plot(x, p, linewidth=2)\n",
    "axs[1].set_title(f\"Gaussian Fit\\nμ={mu:.5f}, σ={std:.5f}\")\n",
    "axs[1].set_xlabel(\"Latitude Difference\")\n",
    "axs[1].set_ylabel(\"Density\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1f179f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "data = df['dist_next_long'].dropna()\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axs[0].boxplot(data, vert=True, showfliers=True)\n",
    "axs[0].set_title(\"Boxplot dist_next_long\")\n",
    "axs[0].set_ylabel(\"Longitude Difference\")\n",
    "axs[0].grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "axs[1].hist(data, bins=30, density=True, alpha=0.6)\n",
    "\n",
    "mu, std = norm.fit(data)\n",
    "\n",
    "x = np.linspace(data.min(), data.max(), 100)\n",
    "p = norm.pdf(x, mu, std)\n",
    "\n",
    "axs[1].plot(x, p, linewidth=2)\n",
    "axs[1].set_title(f\"Gaussian Fit\\nμ={mu:.5f}, σ={std:.5f}\")\n",
    "axs[1].set_xlabel(\"Longitude Difference\")\n",
    "axs[1].set_ylabel(\"Density\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac28436",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['lat'].max(), df['lat'].min())\n",
    "print(df['long'].max(), df['long'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e08fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find how many lat points that will be set as the center poin for the pivot center\n",
    "print(f\"min: {df['lat'].min()}\")\n",
    "for i in range(int(df['lat'].min()), int(df['lat'].max()), 60):\n",
    "    print(i)\n",
    "print(f\"max: {df['lat'].max()}\")\n",
    "\n",
    "'''\n",
    "min: -89.153062\n",
    "-89\n",
    "-29\n",
    "31\n",
    "max: 89.255691\n",
    "'''\n",
    "\n",
    "# take -89, -29, 31, 89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c7102d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find how many long points that will be set as the center poin for the pivot center\n",
    "\n",
    "print(f\"min: {df['long'].min()}\")\n",
    "for i in range(int(df['long'].min()), int(df['long'].max()), 60):\n",
    "    print(i)\n",
    "print(f\"max: {df['long'].max()}\")\n",
    "\n",
    "'''\n",
    "min: -177.386922\n",
    "-177\n",
    "-117\n",
    "-57\n",
    "3\n",
    "63\n",
    "123\n",
    "max: 165.523263\n",
    "'''\n",
    "\n",
    "# take -177, -57, 3, 63, 123"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aabfae9",
   "metadata": {},
   "source": [
    "#### Check The Circle Radius Coverage **[FFAILED]**\n",
    "`BECAUSE NEED EXTRA STUFF TO DO GUARANTEE THAT ALL POINTS WILL BE COVERAGE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427cbfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lats = [-89, -29, 31, 89]\n",
    "longs = [-177, -57, 3, 63, 123]\n",
    "\n",
    "coverage_res = []\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # radius bumi (km)\n",
    "\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "\n",
    "    a = np.sin(dlat / 2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "\n",
    "    return R * c\n",
    "\n",
    "def do_coverage(row, dist=5000):\n",
    "    coverage_res = []\n",
    "\n",
    "    point_lat = row['lat']\n",
    "    point_lon = row['long']\n",
    "\n",
    "    for lat in lats:\n",
    "        for lon in longs:\n",
    "            d = haversine(point_lat, point_lon, lat, lon)\n",
    "            if d <= dist:\n",
    "                coverage_res.append({\n",
    "                    \"center_lat\": lat,\n",
    "                    \"center_lon\": lon,\n",
    "                    \"dist_km\": d\n",
    "                })\n",
    "\n",
    "    return coverage_res\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5357d640",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['circle_coverage'] = df.apply(do_coverage, axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be85606",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['circle_coverage'].apply(len) == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d05f04",
   "metadata": {},
   "source": [
    "#### Check The Grid Area Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fca2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_bins = [(-90, 0), (0, 90)]\n",
    "lon_bins = [\n",
    "    (-180, -90), (-90, 0), \n",
    "    (0, 90), (90, 180)\n",
    "]\n",
    "\n",
    "grid_area_lists = []\n",
    "\n",
    "area_id = 1\n",
    "for lat_min, lat_max in lat_bins:\n",
    "    for lon_min, lon_max in lon_bins:\n",
    "        grid_area_lists.append({\n",
    "            \"name\": f\"AREA {area_id}\",\n",
    "            \"lat_min\": lat_min,\n",
    "            \"lat_max\": lat_max,\n",
    "            \"lon_min\": lon_min,\n",
    "            \"lon_max\": lon_max,\n",
    "        })\n",
    "        area_id += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5decdf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(grid_area_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6820f494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def under_the_area(point_lat, point_lon, area):\n",
    "    isUnder = (\n",
    "        area[\"lat_min\"] <= point_lat < area[\"lat_max\"] and\n",
    "        area[\"lon_min\"] <= point_lon < area[\"lon_max\"]\n",
    "    )\n",
    "\n",
    "    center_lat = (area[\"lat_min\"] + area[\"lat_max\"]) / 2\n",
    "    center_lon = (area[\"lon_min\"] + area[\"lon_max\"]) / 2\n",
    "\n",
    "    dlat = point_lat - center_lat\n",
    "    dlon = point_lon - center_lon\n",
    "\n",
    "    return isUnder, dlat, dlon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fec8e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_coverage(row):\n",
    "    coverage_res = []\n",
    "\n",
    "    point_lat = row['lat']\n",
    "    point_lon = row['long']\n",
    "\n",
    "    for area in grid_area_lists:\n",
    "        isUnder, dlat, dlong = under_the_area(\n",
    "            point_lat,\n",
    "            point_lon,\n",
    "            area\n",
    "        )\n",
    "\n",
    "        if isUnder:\n",
    "            coverage_res.append({\n",
    "                \"area\": area[\"name\"],\n",
    "                \"lat_min\": area[\"lat_min\"],\n",
    "                \"lat_max\": area[\"lat_max\"],\n",
    "                \"lon_min\": area[\"lon_min\"],\n",
    "                \"lon_max\": area[\"lon_max\"],\n",
    "                \"delta_lat\": round(dlat, 4),\n",
    "                \"delta_long\": round(dlong, 4),\n",
    "            })\n",
    "    print(coverage_res)\n",
    "    return coverage_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a4759d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['grid_coverage'] = df.apply(do_coverage, axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1b5624",
   "metadata": {},
   "source": [
    "### Create The Data Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c653c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def build_grid_index(lat_bins, lon_bins):\n",
    "    grid = []\n",
    "\n",
    "    area_id = 1\n",
    "\n",
    "    for lat_min, lat_max in lat_bins:\n",
    "        for lon_min, lon_max in lon_bins:\n",
    "            grid.append({\n",
    "                \"index\": f\"Area_{area_id}\",\n",
    "                \"minimum-latitude\": lat_min,\n",
    "                \"maximum-latitude\": lat_max,\n",
    "                \"minimum-longitude\": lon_min,\n",
    "                \"maximum-longitude\": lon_max,\n",
    "            })\n",
    "            area_id += 1\n",
    "\n",
    "    return grid\n",
    "\n",
    "\n",
    "def find_grid(lat, lon, grid):\n",
    "    for area in grid:\n",
    "        if (\n",
    "            (\n",
    "                area[\"minimum-latitude\"] <= lat\n",
    "                and\n",
    "                lat < area[\"maximum-latitude\"]\n",
    "            )\n",
    "            and\n",
    "            (\n",
    "                area[\"minimum-longitude\"] <= lon\n",
    "                and\n",
    "                lon < area[\"maximum-longitude\"]\n",
    "            )\n",
    "        ):\n",
    "            return area[\"index\"]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def data_splitter(data_list, grid):\n",
    "    data_container = defaultdict(list)\n",
    "\n",
    "    for data in data_list:\n",
    "        lat = data[\"latitude\"]\n",
    "        lon = data[\"longitude\"]\n",
    "        area = find_grid(lat, lon, grid)\n",
    "\n",
    "        if area:\n",
    "            data_container[area].append(data)\n",
    "        else:\n",
    "            data_container[\"OOB\"].append(data)\n",
    "\n",
    "    return dict(data_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3466aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# latitude and longitude boundaries \n",
    "\n",
    "lat_bins = [(-90, -30), (-30, 30), (30, 90)]\n",
    "lon_bins = [\n",
    "    (-180, -120), (-120, -60), (-60, 0),\n",
    "    (0, 60), (60, 120), (120, 180)\n",
    "]\n",
    "\n",
    "GRID = build_grid_index(lat_bins, lon_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610958a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(GRID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8f8a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_splited = data_splitter(datafile, GRID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef476fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_splited.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e782b6e",
   "metadata": {},
   "source": [
    "### Create Data Splitter Converter Into JSON so WE can Just Insert the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0459c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "\n",
    "def convert(data, name):\n",
    "    try:\n",
    "        with open(name, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, indent=4)\n",
    "            print(f\"JSON in FILE {name} created!!\")\n",
    "    except Exception as E:\n",
    "        print(f\"Error happened {str(E)}\")\n",
    "\n",
    "def convert_all_data_container(data_splited):\n",
    "    file_names = []\n",
    "    for k, item in data_splited.items():\n",
    "        fname = f\"./data/{k}.json\"\n",
    "        convert(item, name=fname)\n",
    "        file_names.append(fname)\n",
    "    \n",
    "    return file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc86e77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_all_data_container(data_splited)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f916e4d9",
   "metadata": {},
   "source": [
    "## Implementation Of \n",
    "`How Using The Class Clustering Data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9925f67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class from the ./version/module.py\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "\n",
    "class DataSplitter:\n",
    "    def __init__(\n",
    "        self,\n",
    "    ):\n",
    "        # may be this is not nescesary at all\n",
    "        self.dataSplited = None\n",
    "\n",
    "        self.LAT_BINS = [(-90, -30), (-30, 30), (30, 90)]\n",
    "        self.LON_BINS = [\n",
    "            (-180, -120), (-120, -60), (-60, 0),\n",
    "            (0, 60), (60, 120), (120, 180)\n",
    "        ]\n",
    "\n",
    "        self.GRID = self.build_grid_index(self.LAT_BINS, self.LON_BINS)\n",
    "\n",
    "    def build_grid_index(self, lat_bins, lon_bins):\n",
    "        grid = []\n",
    "\n",
    "        area_id = 1\n",
    "\n",
    "        for lat_min, lat_max in lat_bins:\n",
    "            for lon_min, lon_max in lon_bins:\n",
    "                grid.append({\n",
    "                    \"index\": f\"Area_{area_id}\",\n",
    "                    \"minimum_latitude\": lat_min,\n",
    "                    \"maximum_latitude\": lat_max,\n",
    "                    \"minimum_longitude\": lon_min,\n",
    "                    \"maximum_longitude\": lon_max,\n",
    "                })\n",
    "                area_id += 1\n",
    "\n",
    "        return grid\n",
    "\n",
    "    def find_grid(self, lat, lon, grid):\n",
    "        for area in grid:\n",
    "            if (\n",
    "                (\n",
    "                    area[\"minimum_latitude\"] <= lat\n",
    "                    and\n",
    "                    lat < area[\"maximum_latitude\"]\n",
    "                )\n",
    "                and\n",
    "                (\n",
    "                    area[\"minimum_longitude\"] <= lon\n",
    "                    and\n",
    "                    lon < area[\"maximum_longitude\"]\n",
    "                )\n",
    "            ):\n",
    "                return area[\"index\"]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def data_splitter(self, data_list, grid):\n",
    "        data_container = defaultdict(list)\n",
    "\n",
    "        for data in data_list:\n",
    "            lat = data[\"latitude\"]\n",
    "            lon = data[\"longitude\"]\n",
    "            area = self.find_grid(lat, lon, grid)\n",
    "\n",
    "            if area:\n",
    "                data_container[area].append(data)\n",
    "            else:\n",
    "                data_container[\"OOB\"].append(data)\n",
    "\n",
    "        return dict(data_container)\n",
    "\n",
    "    def convert(self, data, name):\n",
    "        try:\n",
    "            with open(name, 'w', encoding='utf-8') as f:\n",
    "                json.dump(data, f, indent=4)\n",
    "                print(f\"JSON in FILE {name} created!!\")\n",
    "        except Exception as E:\n",
    "            print(f\"Error happened {str(E)}\")\n",
    "\n",
    "    def convert_all_data_container(self, data_splited):\n",
    "        for k, item in data_splited.items():\n",
    "            self.convert(item, name=f\"./data/{k}.json\")\n",
    "\n",
    "    # incase the data loaded as the pandas dataframe\n",
    "    def CSV2JSON_Convert(self, dataframe):\n",
    "        json_data = dataframe.to_json(orientation=\"records\", indent=4)\n",
    "        json_data = json.loads(json_data)\n",
    "        return json_data\n",
    "\n",
    "    def UploadToDatabase(\n",
    "        self, \n",
    "        DB_URI, DB_NAME, \n",
    "        COLLECTION_NAME, data_list\n",
    "    ):\n",
    "        try:\n",
    "            client = pymongo.MongoClient(DB_URI)\n",
    "\n",
    "            db = client[DB_NAME]\n",
    "\n",
    "            collection = db[COLLECTION_NAME]\n",
    "\n",
    "            collection.insert_many(data_list)\n",
    "\n",
    "            print(\n",
    "                f\"Data stored in DB: {DB_NAME}, Collection: {COLLECTION_NAME}\"\n",
    "            )\n",
    "\n",
    "        except Exception as E:\n",
    "            print(f\"Error happened: {str(E)}\")\n",
    "\n",
    "\n",
    "    def runSplit(self, dataJSON):\n",
    "        grid = self.GRID\n",
    "        data_splited = self.data_splitter(dataJSON, grid)\n",
    "        self.result_files = self.convert_all_data_container(data_splited)\n",
    "        self.dataSplited = data_splited\n",
    "    \n",
    "    def UploadData(self, DB_URI, DB_NAME):\n",
    "        res_temp = []\n",
    "        for k, item in self.dataSplited.items():\n",
    "            self.UploadToDatabase(DB_URI, DB_NAME, k, item)\n",
    "            res_temp.append({\"DB_NAME\": DB_NAME, \"COL_NAME\": k})\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bd33e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spliter = DataSplitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244001a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy data first\n",
    "\n",
    "'''\n",
    "data json must be consist of [{...}, {...}, ..., {...},]\n",
    "where the {...} consist of \n",
    "- _id: int or str\n",
    "- latitude: float\n",
    "- longitude: float\n",
    "'''\n",
    "fname = \"data/generated.json\"\n",
    "\n",
    "datafile = None\n",
    "\n",
    "try:\n",
    "    with open(fname, \"r\") as file:\n",
    "        datafile = json.load(file)\n",
    "\n",
    "except json.JSONDecodeError as e:\n",
    "    print(\"Failed to decode JSON:\", e)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"The file was not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0172c082",
   "metadata": {},
   "outputs": [],
   "source": [
    "spliter.runSplit(datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a42553",
   "metadata": {},
   "outputs": [],
   "source": [
    "spliter.dataSplited.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51495200",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "DB_URI = os.getenv(\"MONGODB_URI_CONNECTION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a52d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "spliter.UploadData(DB_URI=DB_URI, DB_NAME=\"hydrolab-database-v0\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.9.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
